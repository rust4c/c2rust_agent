# ============================================================================
# C2Rust Agent 配置文件
# ============================================================================
#
# 重要提醒：
# 请将此文件重命名为 config.toml 并复制到 config/ 目录下使用
#
# 使用步骤：
# 1. cp config/config.default.toml config/config.toml
# 2. 根据你的环境修改相应的配置项
# 3. 确保API密钥等敏感信息已正确填写
#
# ============================================================================

# ============================================================================
# LLM 配置 (llm_requester模块)
# ============================================================================
# 当前使用的 LLM 服务提供商
# 支持的选项: "ollama", "openai", "xai", "deepseek"
provider = "deepseek"

# ============================================================================
# 主处理器配置 (main_processor模块)
# ============================================================================
# 最大重试次数 - 当处理失败时的重试次数限制
max_retry_attempts = 3

# 并发限制 - 同时处理的任务数量限制
concurrent_limit = 5

# ============================================================================
# LLM 服务提供商配置
# ============================================================================

# ----------------------------------------------------------------------------
# Ollama 本地 LLM 配置
# ----------------------------------------------------------------------------
[llm.ollama]
# 使用的模型名称
model = "deepseek-r1:7b"
# Ollama 服务的基础URL
base_url = "http://localhost:11434"
# API密钥 (本地Ollama通常不需要)
api_key = ""

# ----------------------------------------------------------------------------
# OpenAI GPT 配置
# ----------------------------------------------------------------------------
[llm.openai]
# 使用的模型名称 (如: gpt-3.5-turbo, gpt-4, gpt-4-turbo-preview等)
model = "gpt-3.5-turbo"
# OpenAI API密钥 - 请替换为你的真实API密钥
api_key = "your_openai_api_key_here"

# ----------------------------------------------------------------------------
# xAI Grok 配置
# ----------------------------------------------------------------------------
[llm.xai]
# 使用的xAI模型名称
model = "grok-beta"
# xAI API密钥 - 请替换为你的真实API密钥
api_key = "your_xai_api_key_here"

# ----------------------------------------------------------------------------
# DeepSeek 配置
# ----------------------------------------------------------------------------
[llm.deepseek]
# 使用的DeepSeek模型名称
model = "deepseek-chat"
# DeepSeek API密钥 - 请替换为你的真实API密钥
api_key = "sk-your_deepseek_api_key_here"

# ============================================================================
# 文本分块配置 (llm_requester模块)
# ============================================================================
[chunking]
# 是否启用文本分块功能
enabled = true
# 每个分块的最大token数量
max_tokens = 120000
# 分块间的重叠token数量 (用于保持上下文连贯性)
chunk_overlap = 100

# ============================================================================
# 数据库配置 (db_services模块)
# ============================================================================

# ----------------------------------------------------------------------------
# Qdrant 向量数据库配置
# ----------------------------------------------------------------------------
[qdrant]
# Qdrant 服务器主机地址, 如果环境为 docker-compose 需要更改为 “qdrant”
host = "localhost"
# Qdrant 服务器端口 (可选，默认6334)
port = 6334
# 向量集合名称
collection_name = "c2rust_vectors"
# 向量维度大小 (需要与嵌入模型匹配, 如使用其它模型请相应调整)
vector_size = 1024

# ----------------------------------------------------------------------------
# SQLite 数据库配置
# ----------------------------------------------------------------------------
[sqlite]
# SQLite 数据库文件路径 (相对于项目根目录)
# 支持绝对路径和相对路径
path = "data.db"

# ============================================================================
# C 项目预处理配置 (cproject_analy/file_remanager)
# ============================================================================
[cproject.preprocess]
# 0 表示自动选择（保留为 0 给运行时处理）
worker_count = 0

# 排除文件/目录模式
exclude_patterns = [
  "*.bak",
  "*.tmp",
  "__pycache__/*",
  "*.pyc",
  ".git/*",
  ".svn/*",
  "*.o",
  "*.obj",
  "*.exe",
  "*.dll",
  "*.so",
]

# 头文件与源文件扩展名
header_extensions = [".h", ".hpp", ".hh", ".hxx"]
source_extensions = [".c", ".cc", ".cpp", ".cxx", ".c++"]

# 大文件阈值 (字节) 与块大小 (字节)
large_file_threshold = 52428800 # 50MB
chunk_size = 8388608            # 8MB

# uv 工具配置
uv_command = "uv"
uv_venv_path = ".compiledb-venv"

[[cproject.preprocess.uv_mirrors]]
name = "PyPI"

[[cproject.preprocess.uv_mirrors]]
name = "Tsinghua"
index_url = "https://pypi.tuna.tsinghua.edu.cn/simple"

[[cproject.preprocess.uv_mirrors]]
name = "Aliyun"
index_url = "https://mirrors.aliyun.com/pypi/simple"

[[cproject.preprocess.uv_mirrors]]
name = "USTC"
index_url = "https://pypi.mirrors.ustc.edu.cn/simple"

# 文件配对规则（多段）
[[cproject.preprocess.pairing_rules]]
source = "(.+)\\.c"
header = "\\1.h"

[[cproject.preprocess.pairing_rules]]
source = "(.+)\\.cpp"
header = "\\1.h"

[[cproject.preprocess.pairing_rules]]
source = "src/(.+)\\.c"
header = "include/\\1.h"

# ============================================================================
# 单个处理器配置 (single_processor模块)
# ============================================================================
# 注意: single_processor 模块使用与 main_processor 相同的 max_retry_attempts 配置
# 如需单独配置，可以在此添加 [single_processor] 段落

# ============================================================================
# 安全注意事项
# ============================================================================
# 1. 请勿将包含真实API密钥的配置文件提交到版本控制系统
# 2. 建议使用环境变量来存储敏感信息
# 3. 定期轮换API密钥以提高安全性
# 4. 确保配置文件权限设置正确，避免未授权访问
#
# ============================================================================
# 故障排查
# ============================================================================
# 1. 如果配置文件未找到，检查文件路径是否正确
# 2. 如果API调用失败，检查API密钥和网络连接
# 3. 如果数据库连接失败，检查数据库服务是否运行
# 4. 查看日志文件获取详细错误信息
#
# ============================================================================
