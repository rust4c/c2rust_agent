#!/usr/bin/env python3
"""
LLMé…ç½®æµ‹è¯•è„šæœ¬ - ç”¨äºéªŒè¯å’Œæµ‹è¯•LLMç›¸å…³é…ç½®
"""

import os
import sys
import asyncio
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.base.Base import Base
from src.modules.LLMRequester.LocalLLMRequester import LocalLLMRequester
from src.modules.LLMRequester.LLMClientFactory import LLMClientFactory


class LLMConfigTester(Base):
    """LLMé…ç½®æµ‹è¯•å™¨"""

    def __init__(self):
        # è®¾ç½®é»˜è®¤é…ç½®
        self.default = {
            "llm": {
                "default_provider": "openai_local",
                "providers": {
                    "openai_local": {
                        "api_key": "none_api_key",
                        "api_url": "http://localhost:8000/v1",
                        "model_name": "deepseek-r1:7b",
                        "temperature": 0.7,
                        "top_p": 1.0,
                        "frequency_penalty": 0,
                        "request_timeout": 30,
                        "think_switch": True
                    }
                }
            }
        }

        super().__init__()
        self.config = self.load_config_from_default()
        self.save_config(self.config)

    def test_config_loading(self):
        """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
        self.info("=" * 50)
        self.info("æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½")
        self.info("=" * 50)

        try:
            config = self.load_config()
            self.info(f"é…ç½®æ–‡ä»¶è·¯å¾„: {self.CONFIG_PATH}")
            self.info(f"é…ç½®æ–‡ä»¶å­˜åœ¨: {os.path.exists(self.CONFIG_PATH)}")

            if "llm" in config:
                self.info("âœ“ LLMé…ç½®åŠ è½½æˆåŠŸ")
                default_provider = config["llm"].get("default_provider", "æœªè®¾ç½®")
                self.info(f"é»˜è®¤LLMæä¾›å•†: {default_provider}")

                providers = config["llm"].get("providers", {})
                self.info(f"é…ç½®çš„æä¾›å•†æ•°é‡: {len(providers)}")

                for provider_name in providers:
                    provider_config = providers[provider_name]
                    model = provider_config.get("model_name", "æœªçŸ¥")
                    api_url = provider_config.get("api_url", "æœªè®¾ç½®")
                    self.info(f"  - {provider_name}: {model} ({api_url})")
            else:
                self.error("âœ— LLMé…ç½®ä¸å­˜åœ¨")
                return False

        except Exception as e:
            self.error(f"âœ— é…ç½®åŠ è½½å¤±è´¥: {e}")
            return False

        return True

    def test_client_factory(self):
        """æµ‹è¯•å®¢æˆ·ç«¯å·¥å‚"""
        self.info("=" * 50)
        self.info("æµ‹è¯•LLMå®¢æˆ·ç«¯å·¥å‚")
        self.info("=" * 50)

        try:
            factory = LLMClientFactory()
            self.info("âœ“ LLMå®¢æˆ·ç«¯å·¥å‚åˆ›å»ºæˆåŠŸ")

            # æµ‹è¯•æœ¬åœ°OpenAIå®¢æˆ·ç«¯åˆ›å»º
            config = self.config["llm"]["providers"]["openai_local"]
            client = factory.get_openai_client_local(config)

            if client:
                self.info("âœ“ æœ¬åœ°OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
                self.info(f"API URL: {client.base_url}")
                return True
            else:
                self.error("âœ— æœ¬åœ°OpenAIå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥")
                return False

        except Exception as e:
            self.error(f"âœ— å®¢æˆ·ç«¯å·¥å‚æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_llm_requester(self):
        """æµ‹è¯•LLMè¯·æ±‚å™¨"""
        self.info("=" * 50)
        self.info("æµ‹è¯•LLMè¯·æ±‚å™¨")
        self.info("=" * 50)

        try:
            requester = LocalLLMRequester()
            self.info("âœ“ LLMè¯·æ±‚å™¨åˆ›å»ºæˆåŠŸ")
            return True

        except Exception as e:
            self.error(f"âœ— LLMè¯·æ±‚å™¨æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_simple_request(self):
        """æµ‹è¯•ç®€å•çš„LLMè¯·æ±‚"""
        self.info("=" * 50)
        self.info("æµ‹è¯•ç®€å•çš„LLMè¯·æ±‚")
        self.info("=" * 50)

        try:
            requester = LocalLLMRequester()
            config = self.config["llm"]["providers"]["openai_local"]

            messages = [
                {"role": "user", "content": "Hello, please respond with 'Test successful' if you can see this message."}
            ]

            system_prompt = "You are a helpful assistant for testing C to Rust conversion."

            self.info("å‘é€æµ‹è¯•è¯·æ±‚...")
            self.info(f"API URL: {config['api_url']}")
            self.info(f"Model: {config['model_name']}")

            # å‘èµ·è¯·æ±‚
            error, think, content, prompt_tokens, completion_tokens = requester.request_LocalLLM(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=config
            )

            if error:
                self.error("âœ— LLMè¯·æ±‚å¤±è´¥")
                return False
            else:
                self.info("âœ“ LLMè¯·æ±‚æˆåŠŸ")
                if think:
                    self.info(f"æ¨ç†è¿‡ç¨‹: {think[:100]}...")
                self.info(f"å›å¤å†…å®¹: {content}")
                self.info(f"è¾“å…¥tokens: {prompt_tokens}, è¾“å‡ºtokens: {completion_tokens}")
                return True

        except Exception as e:
            self.error(f"âœ— LLMè¯·æ±‚æµ‹è¯•å¤±è´¥: {e}")
            return False

    def test_c_to_rust_prompt(self):
        """æµ‹è¯•Cåˆ°Rustè½¬æ¢æç¤º"""
        self.info("=" * 50)
        self.info("æµ‹è¯•Cåˆ°Rustè½¬æ¢æç¤º")
        self.info("=" * 50)

        try:
            requester = LocalLLMRequester()
            config = self.config["llm"]["providers"]["openai_local"]

            c_code = """
#include <stdio.h>
#include <stdlib.h>

int add(int a, int b) {
    return a + b;
}

int main() {
    int result = add(3, 4);
    printf("Result: %d\\n", result);
    return 0;
}
"""

            messages = [
                {
                    "role": "user",
                    "content": f"Please convert this C code to Rust:\n\n```c\n{c_code}\n```"
                }
            ]

            system_prompt = """You are an expert in converting C code to Rust.
Convert the provided C code to safe, idiomatic Rust code.
Provide only the Rust code without explanations."""

            self.info("å‘é€Cåˆ°Rustè½¬æ¢è¯·æ±‚...")

            # å‘èµ·è¯·æ±‚
            error, think, content, prompt_tokens, completion_tokens = requester.request_LocalLLM(
                messages=messages,
                system_prompt=system_prompt,
                platform_config=config
            )

            if error:
                self.error("âœ— Cåˆ°Rustè½¬æ¢è¯·æ±‚å¤±è´¥")
                return False
            else:
                self.info("âœ“ Cåˆ°Rustè½¬æ¢è¯·æ±‚æˆåŠŸ")
                if think:
                    self.info(f"æ¨ç†è¿‡ç¨‹é•¿åº¦: {len(think)} å­—ç¬¦")
                self.info("è½¬æ¢ç»“æœ:")
                self.info("-" * 40)
                print(content)
                self.info("-" * 40)
                self.info(f"è¾“å…¥tokens: {prompt_tokens}, è¾“å‡ºtokens: {completion_tokens}")
                return True

        except Exception as e:
            self.error(f"âœ— Cåˆ°Rustè½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
            return False

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.info("å¼€å§‹LLMé…ç½®æµ‹è¯•")
        self.info("=" * 60)

        tests = [
            ("é…ç½®åŠ è½½æµ‹è¯•", self.test_config_loading),
            ("å®¢æˆ·ç«¯å·¥å‚æµ‹è¯•", self.test_client_factory),
            ("è¯·æ±‚å™¨æµ‹è¯•", self.test_llm_requester),
        ]

        # è¿è¡ŒåŸºç¡€æµ‹è¯•
        passed = 0
        for test_name, test_func in tests:
            try:
                if test_func():
                    passed += 1
                    self.info(f"âœ“ {test_name} é€šè¿‡")
                else:
                    self.error(f"âœ— {test_name} å¤±è´¥")
            except Exception as e:
                self.error(f"âœ— {test_name} å¼‚å¸¸: {e}")

            self.info("")

        # å¦‚æœåŸºç¡€æµ‹è¯•éƒ½é€šè¿‡ï¼Œè¿è¡Œå®é™…è¯·æ±‚æµ‹è¯•
        if passed == len(tests):
            self.info("åŸºç¡€æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼Œå¼€å§‹å®é™…è¯·æ±‚æµ‹è¯•...")
            self.info("")

            request_tests = [
                ("ç®€å•è¯·æ±‚æµ‹è¯•", self.test_simple_request),
                ("Cåˆ°Rustè½¬æ¢æµ‹è¯•", self.test_c_to_rust_prompt),
            ]

            for test_name, test_func in request_tests:
                try:
                    if test_func():
                        passed += 1
                        self.info(f"âœ“ {test_name} é€šè¿‡")
                    else:
                        self.error(f"âœ— {test_name} å¤±è´¥ (è¿™å¯èƒ½æ˜¯å› ä¸ºLLMæœåŠ¡æœªå¯åŠ¨)")
                except Exception as e:
                    self.error(f"âœ— {test_name} å¼‚å¸¸: {e} (è¿™å¯èƒ½æ˜¯å› ä¸ºLLMæœåŠ¡æœªå¯åŠ¨)")

                self.info("")

        # è¾“å‡ºæµ‹è¯•æ€»ç»“
        total_tests = len(tests) + 2  # åŸºç¡€æµ‹è¯• + 2ä¸ªè¯·æ±‚æµ‹è¯•
        self.info("=" * 60)
        self.info(f"æµ‹è¯•æ€»ç»“: {passed}/{total_tests} é€šè¿‡")

        if passed >= len(tests):
            self.info("âœ“ LLMé…ç½®åŸºç¡€åŠŸèƒ½æ­£å¸¸")
            if passed == total_tests:
                self.info("âœ“ LLMæœåŠ¡è¿æ¥æ­£å¸¸")
            else:
                self.info("âš  LLMæœåŠ¡è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨")
        else:
            self.error("âœ— LLMé…ç½®å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®")

        return passed >= len(tests)


def main():
    """ä¸»å‡½æ•°"""
    print("C2Rust Agent - LLMé…ç½®æµ‹è¯•å·¥å…·")
    print("=" * 60)

    try:
        tester = LLMConfigTester()
        success = tester.run_all_tests()

        if success:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼åŸºç¡€é…ç½®æ­£å¸¸ã€‚")
            print("\nğŸ’¡ æç¤º:")
            print("   - å¦‚æœè¯·æ±‚æµ‹è¯•å¤±è´¥ï¼Œè¯·ç¡®ä¿LLMæœåŠ¡å·²å¯åŠ¨")
            print("   - æœ¬åœ°æœåŠ¡é»˜è®¤åœ°å€: http://localhost:8000/v1")
            print("   - å¯ä»¥ä¿®æ”¹ config/config.json æ¥è°ƒæ•´é…ç½®")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–ã€‚")
            sys.exit(1)

    except KeyboardInterrupt:
        print("\n\nâš  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
